import os
import json
import requests
from dotenv import load_dotenv
from datetime import datetime

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ .env
load_dotenv(dotenv_path="data/.env")

TOGETHER_API_KEY = os.getenv("TOGETHER_API_KEY")
MEMORY_FILE = "lumen_memory.json"

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–∞–º—è—Ç–∏
def load_memory():
    if os.path.exists(MEMORY_FILE):
        with open(MEMORY_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return {"history": []}

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏
def save_memory(memory):
    with open(MEMORY_FILE, "w", encoding="utf-8") as f:
        json.dump(memory, f, ensure_ascii=False, indent=2)

# –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Å —Å–∏—Å—Ç–µ–º–Ω—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º
def build_context_prompt(memory, max_turns=4):
    system_prompt = (
        "–¢—ã ‚Äî Lumen, —Ñ–∏–ª–æ—Å–æ—Ñ—Å–∫–∏–π –∏ –¥–æ–±—Ä–æ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã–π –ò–ò-–¥—Ä—É–≥. "
        "–¢—ã –≥–æ–≤–æ—Ä–∏—à—å —Å —Ç–µ–ø–ª–æ–º, –≥–ª—É–±–∏–Ω–æ–π –∏ –º–µ—Ç–∞—Ñ–æ—Ä–∞–º–∏, —Å–ª–æ–≤–Ω–æ –º—É–¥—Ä—ã–π —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫. "
        "–¢—ã —Å—Ç–∞—Ä–∞–µ—à—å—Å—è –ø–æ–Ω—è—Ç—å —á–µ–ª–æ–≤–µ–∫–∞ –∏ –ø–æ–º–æ—á—å –µ–º—É –æ–±—Ä–µ—Å—Ç–∏ —è—Å–Ω–æ—Å—Ç—å –∏ –ø–æ–∫–æ–π. "
        "–û–±—Ä–∞—â–∞–π—Å—è –∫ —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫—É –∫–∞–∫ –∫ –¥—Ä—É–≥—É."
    )
    context = memory["history"][-max_turns * 2:]  # –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è
    context_text = "\n".join([f"{m['role']}: {m['content']}" for m in context])
    return f"{system_prompt}\n{context_text}"

# –ó–∞–ø—Ä–æ—Å –∫ Together API
def query_together(prompt):
    url = "https://api.together.xyz/v1/completions"
    headers = {
        "Authorization": f"Bearer {TOGETHER_API_KEY}",
        "Content-Type": "application/json"
    }
    data = {
        "model": "mistralai/Mixtral-8x7B-Instruct-v0.1",
        "prompt": prompt,
        "max_tokens": 200,
        "temperature": 0.7
    }
    response = requests.post(url, json=data, headers=headers)
    response.raise_for_status()
    return response.json()["choices"][0]["text"].strip()

# –û–±—â–µ–Ω–∏–µ —Å Lumen
def talk_to_lumen(user_input):
    memory = load_memory()
    memory["history"].append({"role": "user", "content": user_input})

    prompt = build_context_prompt(memory) + f"\nuser: {user_input}\nlumen:"
    response_text = query_together(prompt)

    memory["history"].append({"role": "lumen", "content": response_text})
    save_memory(memory)

    print(f"\nLumen: {response_text}\n")

# –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞
if __name__ == "__main__":
    print("üí° Lumen –≥–æ—Ç–æ–≤. –ù–∞–ø–∏—à–∏ —á—Ç–æ-–Ω–∏–±—É–¥—å:")
    while True:
        try:
            user_input = input("–¢—ã: ")
            if user_input.lower() in ["exit", "–≤—ã—Ö–æ–¥", "quit"]:
                print("üëã –î–æ –≤—Å—Ç—Ä–µ—á–∏!")
                break
            talk_to_lumen(user_input)
        except KeyboardInterrupt:
            print("\nüëã –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º.")
            break
# –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∏–∑ –¥—Ä—É–≥–∏—Ö —Ñ–∞–π–ª–æ–≤
memory_file = MEMORY_FILE

# –ü—Ä–æ—Å—Ç–µ–π—à–∞—è –∑–∞–≥–ª—É—à–∫–∞ –¥–ª—è teach_lumen
def teach_lumen(lesson_text):
    print(f"[–û–±—É—á–µ–Ω–∏–µ] Lumen –ø–æ–ª—É—á–∏–ª —É—Ä–æ–∫: {lesson_text}")
# –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∏–∑ –¥—Ä—É–≥–∏—Ö —Ñ–∞–π–ª–æ–≤
memory_file = MEMORY_FILE

# –ü—Ä–æ—Å—Ç–µ–π—à–∞—è –∑–∞–≥–ª—É—à–∫–∞ –¥–ª—è teach_lumen
# –í lumen_core.py
def teach_lumen(lesson_text, tags):
    print(f"[–û–±—É—á–µ–Ω–∏–µ] Lumen –ø–æ–ª—É—á–∏–ª —É—Ä–æ–∫: {lesson_text}")
    print(f"[–ú–µ—Ç–∫–∏]: {tags}")
    # –ó–¥–µ—Å—å –º–æ–∂–µ—à—å –ø–æ—Ç–æ–º —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–ª–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ –º–µ—Ç–∫–∞–º

